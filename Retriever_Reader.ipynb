{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43327c63",
   "metadata": {},
   "source": [
    "# Retriever and Reader\n",
    "In this notebook we implement the dense passage retriever, that returns the most probable document and passage for answering the question. The reader, on the other hand, processes the passage, in order to extract the specific answer to the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "007e86f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "from haystack.nodes import DensePassageRetriever, BM25Retriever, EmbeddingRetriever\n",
    "import os\n",
    "from haystack.nodes import FARMReader,TransformersReader\n",
    "from haystack.pipelines import ExtractiveQAPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534f8456",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6abe39",
   "metadata": {},
   "source": [
    "# Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b32d4a",
   "metadata": {},
   "source": [
    "<b>ds_astronomy:</b> document store with processed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f873c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "host = os.environ.get(\"ELASTICSEARCH_HOST\", \"localhost\")\n",
    "\n",
    "ds_astronomy = ElasticsearchDocumentStore(\n",
    "    host=host,\n",
    "    username=\"\",\n",
    "    password=\"\",\n",
    "    index=\"ds_astronomy\",\n",
    "    similarity=\"dot_product\",\n",
    "    embedding_dim=768\n",
    ")\n",
    "\n",
    "curr_store = ds_astronomy\n",
    "localhost = 'http://localhost:9200/ds_astronomy/_count'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63b2e809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF Retriever\n",
    "retriever = DensePassageRetriever(\n",
    "    document_store=ds_astronomy,\n",
    "    query_embedding_model='facebook/dpr-question_encoder-single-nq-base',\n",
    "    passage_embedding_model='facebook/dpr-ctx_encoder-single-nq-base',\n",
    "    use_gpu=True,\n",
    "    embed_title=True\n",
    ")\n",
    "ds_astronomy.update_embeddings(retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55f87dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:haystack.nodes.retriever._embedding_encoder:You are using a Sentence Transformer with the dot_product function. We recommend using cosine instead. This can be set when initializing the DocumentStore\n"
     ]
    }
   ],
   "source": [
    "# EmbeddingRetriever Retriever\n",
    "\n",
    "#Worst performing\n",
    "retriever = EmbeddingRetriever(\n",
    "document_store=ds_astronomy,\n",
    "   embedding_model=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\",\n",
    "   model_format=\"sentence_transformers\"\n",
    ")\n",
    "ds_astronomy.update_embeddings(retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "136e9091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25 Retriever\n",
    "retriever = BM25Retriever(\n",
    "   ds_astronomy\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fee9e6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b0e4b2",
   "metadata": {},
   "source": [
    "<h1>Reader</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08257867",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta = \"deepset/roberta-base-squad2\"\n",
    "\n",
    "reader = FARMReader(\n",
    "    model_name_or_path=roberta, \n",
    "    use_gpu=True, \n",
    "    return_no_answer=True, \n",
    "    no_ans_boost=0, \n",
    "    top_k=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bde572f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0383c21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ExtractiveQAPipeline(reader, retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da4a6b3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ea48226",
   "metadata": {},
   "source": [
    "<h3>Question & Awnser</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c079f0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72771113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PegasusForConditionalGeneration as PCG\n",
    "from transformers import PegasusTokenizerFast as PTF\n",
    "\n",
    "model = PCG.from_pretrained(\"tuner007/pegasus_paraphrase\")\n",
    "tokenizer = PTF.from_pretrained(\"tuner007/pegasus_paraphrase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3c893bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paraphrased_sentences(model, tokenizer, sentence, num_return_sequences=5, num_beams=5):\n",
    "  # tokenize the text to be form of a list of token IDs\n",
    "  inputs = tokenizer([sentence], truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
    "  # generate the paraphrased sentences\n",
    "  outputs = model.generate(\n",
    "    **inputs,\n",
    "    num_beams=num_beams,\n",
    "    num_return_sequences=num_return_sequences,\n",
    "  )\n",
    "  # decode the generated sentences using the tokenizer to get them back to\\ text\n",
    "  list_ = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "  if sentence not in list_:\n",
    "    list_.insert(0, sentence)\n",
    "  return list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b796e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Darck energy\n",
    "q1 = 'Compared to the Sun, what is the mass of white dwarfs stars'\n",
    "q2 = 'Compared to the Sun, what is the size of white dwarfs stars'\n",
    "q3 = 'What are the consequences of the strong gravitational field of the white dwarf'\n",
    "\n",
    "#Dark matter\n",
    "q4 = 'What is ordinary baryonic matter'\n",
    "q5 = 'How abundant is dark matter'\n",
    "q6 = 'What is dark matter'\n",
    "\n",
    "#Geophysical Classification of Planets\n",
    "q7 = 'What is the element composition of rock planets?'\n",
    "q8 = 'Who are the ice giants'\n",
    "q9 = 'What is the composition of ice giants'\n",
    "\n",
    "#Stars\n",
    "q10 = 'What is the Orion Nebula?'\n",
    "q11 = 'How many years until the collapse of our sun'\n",
    "q12 = 'What is the most abundant star in our Universe'\n",
    "\n",
    "#Supernova Stages\n",
    "q13 = 'How many stages does the death of a star have'\n",
    "q14 = 'What is a supernova'\n",
    "q15 = 'What happens to the remains of the former star'\n",
    "\n",
    "#Light\n",
    "q16 = 'What is the whavelenght range that the human eye can see'\n",
    "q17 = 'What happens during a total eclipse'\n",
    "q18 = \"What would happen if the Sun's surface were 3.000 ÂºC cooler?\"\n",
    "\n",
    "#Black Hole\n",
    "q19 = 'What is a black hole?'\n",
    "q20 = 'What resembles the mass of a large mountain'\n",
    "q21 = \"What happens when a very big star falls in upon itself?\"\n",
    "\n",
    "#Sun light\n",
    "q22 = \"What is the source of Earth's light\"\n",
    "q23 = \"What did Einstein show to clue the source of stellar energy\"\n",
    "q24 = 'What did scientists learn about matter?'\n",
    "\n",
    "question_list = [q1, q2, q3, q4, q5, q6, q7, q8, q9, q10, q11, q12, q13, q14, q15, q16, q17, q18, q19, q20, q21, q22, q23, q24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039d0366",
   "metadata": {},
   "outputs": [],
   "source": [
    "for qn in question_list:\n",
    "    print(f'#### {qn}####')\n",
    "    query_list = get_paraphrased_sentences(model, tokenizer, qn, num_beams=5, num_return_sequences=5)\n",
    "\n",
    "    for question in query_list:\n",
    "        start = time.time()\n",
    "        result = pipeline.run(query=question)\n",
    "        print('Question: ', question)\n",
    "        for idx in range(len(result['answers'])):\n",
    "            answer = str(result['answers'][idx])\n",
    "            answer = answer.split(\"answer=\")[1]\n",
    "            answer = answer.split(\", score=\")[0]\n",
    "            print(answer)\n",
    "        end = time.time()\n",
    "        print('Elapsed time: ', end - start)\n",
    "        print(\"----------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c28207cbf101b5fd31f062ed72814c7d2a1b366155535ea78ffa95e3f97ec6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
