Hindawi Publishing Corporation Advances in Astronomy Volume 2011, Article ID 968283, 22pages Dark Matter A Primer Katherine Garrett and Gintaras D ¯uda Department of Physics, Creighton University, 2500 California Plaza, Omaha, NE 68178, USA Correspondence should be addressed to Gintaras D ¯uda, Received 12 June 2010 Accepted 28 September 2010 Academic Editor David Merritt Copyright 2011 Garrett and D ¯uda. This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and repro duction in any medium, provided the original work is properly.
Dark matter is one of the greatest unsolved mysteries in cosmology at the present time. About 80% of the Universe’s gravitating matter is nonluminous, and its nature and distribution are for the most part unknown. In this paper, we will outline the history,astrophysical evidence, candidates, and detection methods of dark matter, with the goal to give the reader an accessible but rigorous introduction to the puzzle of dark matter. This paper targets advanced students and researchers new to the ﬁeld of dark matter, and includes an extensive list of references for further study.
One of the most astounding revelations of the twentieth century in terms of our understanding of the Universe is thatordinary baryonic matter, that is, matter made up of protons and neutrons, is not the dominant form of material in the Universe. Rather, some strange new form of matter, dubbed“dark matter,” ﬁlls our Universe, and it is roughly ﬁve timesmore abundant than ordinary matter. Although we have yetto detect this strange material in the laboratory, there is agreat deal of evidence which points to the necessity of itsexistence.
A complete understanding of dark matter requires utilizing several branches of physics and astronomy. Thecreation of dark matter during the hot expansion of theUniverse is understood through statistical mechanics andthermodynamics. Particle physics is necessary to proposecandidates for dark matter and explore its possible interactions with ordinary matter. General relativity, astrophysics, and cosmology dictate how dark matter acts on largescales and how the Universe may be viewed as a laboratory tostudy dark matter. Many other areas of physics come intoplay as well, making the study of dark matter a diverse andinterdisciplinary ﬁeld. Furthermore, the profusion of groundand satellitebased measurements in recent years have rapidlyadvanced the ﬁeld making it dynamic and timely we are trulyentering the era of “precision cosmology” .This paper aims to give a general overview of the subject of dark matter suitable for nonexperts we hope to treat thisfascinating and important topic in a way such that the nonspecialist will gain a strong foundation and introduction todark matter. It is at times di ﬃcult to ﬁnd understandable and appropriate literature for individuals with no background onthe subject. Existing reviews are either popularlevel pieceswhich are too general or specialized pieces for experts inthe ﬁeld, motivating us to create an accessible overview. Weparticularly hope that this paper will be helpful to graduatestudents beginning their study of dark matter and to otherphysicists and astronomers who would like to learn moreabout this important topic.
T o give such an introduction to dark matter, we will ﬁrst brieﬂy explain the ﬁrst hints that dark matter exists,elaborate on the strong evidence physicists and astronomershave accumulated in the past years, discuss the neutralinoand other possible candidates, and describe various detectionmethods used to probe the dark matter’s mysterious properties. Although we will at times focus on supersymmetric theories of dark matter, other possibilities will be introduced.
2. History and Early Indications Astronomers have long relied on photometry to yieldestimates on mass, speciﬁcally through welldeﬁned mass to.
2 Advances in Astronomy luminosity ratios ML . This is not at all surprising, since visual astronomy relies on the light emitted from distantobjects. For example, the ML ratio for the Sun is ML 5.1×103kgW since this number is not terribly instructive, one usually measures mass to luminosity in terms of the Sun’smass and luminosity such that M L1 by deﬁnition.
Thus by measuring the light output of an object e.g., a galaxy or cluster of galaxies one can use welldeﬁned ML ratios in order to estimate the mass of the object.
In the early 1930s, Oort found that the motion of stars in the Milky Way hinted at the presence of far more galacticmass than anyone had previously predicted. By studying theDoppler shifts of stars moving near the galactic plane, Oortwas able to calculate their velocities, and thus made thestartling discovery that the stars should be moving quicklyenough to escape the gravitational pull of the luminous massin the galaxy. Oort postulated that there must be more masspresent within the Milky Way to hold these stars in theirobserved orbits. However, Oort noted that another possibleexplanation was that 85% of the light from the galactic centerwas obscured by dust and intervening matter or that thevelocity measurements for the stars in question were simplyin error.
Around the same time Oort made his discovery, Swiss astronomer Zwicky found similar indications of missingmass, but on a much larger scale. Zwicky studied the Comacluster, about 99 Mpc 322 million lightyears from Earth,and, using observed Doppler shifts in galactic spectra, wasable to calculate the velocity dispersion of the galaxies inthe Coma cluster. Knowing the velocity dispersions of the individual galaxies i.e., kinetic energy, Zwicky employed the virial theorem to calculate the cluster’s mass. Assumingonly gravitational interactions and Newtonian gravity F 1r2, the virial theorem gives the following relation between kinetic and potential energy whereangbracketleftTangbracketrightis the average kinetic energy and angbracketleftUangbracketrightis the average potential energy. Zwicky found that the total mass of thecluster was M cluster≈4.5×1013M. Since he observed roughly 1000 nebulae in the cluster, Zwicky calculated thatthe average mass of each nebula was M.
This result was startling because a measurement of the massof the cluster using standard ML ratios for nebulae gave a total mass for the cluster approximately 2% of this value.
In essence, galaxies only accounted for only a small fraction of the total mass the vast majority of the mass of theComa cluster was for some reason “missing” or nonluminousalthough not known to Zwicky at the time, roughly 10% ofthe cluster mass is contained in the intracluster gas whichslightly alleviates but does not solve the issue of missingmass.
Roughly 40 years following the discoveries of Oort, Zwicky, and others, Vera Rubin and collaborators conductedan extensive study of the rotation curves of 60 isolatedgalaxies . The galaxies chosen were oriented in such a way so that material on one side of the galactic nucleuswas approaching our galaxy while material on the other sidewas receding thus the analysis of spectral lines Doppler shift gave the rotational velocity of regions of the targetgalaxy. Additionally, the position along the spectral line gaveangular information about the distance of the point from thecenter of the galaxy. Ideally one would target individual starsto determine their rotational velocities however, individual stars in distant galaxies are simply too faint, so Rubin used clouds of gas rich in hydrogen and helium that surround hotstars as tracers of the rotational proﬁle.
It was assumed that the orbits of stars within a galaxy would closely mimic the rotations of the planets within oursolar system. Within the solar system, wherevr is the rotation speed of the object at a radius r, Gis the gravitational constant, and mr is the total mass contained within rfor the solar system essentially the Sun’s mass, which is derived from simply setting the gravitationalforce equal to the centripetal force planetary orbits beingroughly circular. Therefore, vr ∝1√r, meaning that the velocity of a rotating body should decrease as its distancefrom the center increases, which is generally referred to as“Keplerian” behavior.
Rubin’s results showed an extreme deviation from pre dictions due to Newtonian gravity and the luminous matterdistribution. The collected data showed that the rotationcurves for stars are “ﬂat,” that is, the velocities of starscontinue to increase with distance from the galactic center until they reach a limit shown in Figure 1 . An intuitive way to understand this result is through a simpliﬁed model consider the galaxy as a uniform sphere of mass and applyGauss’s law for gravity in direct analogy with Gauss’s Lawfor the electric ﬁeld Svectorg·dvectorA4πGM encl, 3 where the left hand side is the ﬂux of the gravitational ﬁeld through a closed surface and the right hand side isproportional to the total mass enclosed by that surface. If, asthe radius of the Gaussian surface increases, more and moremass in enclosed, then the gravitational ﬁeld will grow herevelocities can grow or remain constant as a function of radiusrwith the exact behavior depending on the mass proﬁle Mr. If, however, the mass enclosed decreases or remains constant as the Gaussian surface grows, then the gravitational ﬁeld will fall, leading to smaller and smaller rotationalvelocities as rincreases. Near the center of the galaxy where the luminous mass is concentrated falls under the formercondition, whereas in the outskirts of the galaxy where littleto no additional mass is being added the majority of thegalaxy’s mass being in the central bulge one expects thesituation to be that of the latter. Therefore, if the rotationalvelocities remain constant with increasing radius, the massinterior to this radius must be increasing. Since the density ofluminous mass falls past the central bulge of the galaxy, the“missing” mass must be nonluminous. Rubin summarized,“The conclusion is inescapable mass, unlike luminosity,.
Advances in Astronomy 3 NGC 3198 data Radius Arcmin20 30 Figure 1 Measured rotational velocities of HI regions in NGC 3198 compared to an idealized Keplerian behavior.
is not concentrated near the center of spiral galaxies. Thus the light distribution in a galaxy is not at all a guide to massdistribution”.
In the 1970s, another way to probe the amount and distribution of dark matter was discovered gravitationallensing. Gravitational lensing is a result of Einstein’s Theoryof Relativity which postulates that the Universe exists withina ﬂexible fabric of spacetime. Objects with mass bend thisfabric, a ﬀecting the motions of bodies around them objects follow geodesics on this curved surface. The motions ofplanets around the Sun can be explained in this way, muchlike how water molecules circle an empty drain. The patho fl i g h ti ss i m i l a r l ya ﬀected light bends when encountering massive objects. T o see the e ﬀects of gravitational lensing, cosmologists look for a relatively close, massive object oftena cluster of galaxies behind which a distant, bright objectoften a galaxy is located there is actual an optimal lensobserver separation, so this must be taken into account aswell. If the distant galaxy were to be located directly behind the cluster, a complete “Einstein ring” would appear this looks much like a bullseye, where the center is the closerobject and the ring is the lensed image of the more distantobject. However, the likelihood of two appropriately brightand distant objects lining up perfectly with the Earth islow thus, distorted galaxies generally appear as “arclets,” orpartial Einstein rings.
In 1979, Walsh et al .were the ﬁrst to observe this form of gravitational lensing. Working at the Kitt Peak NationalObservatory, they found two distant objects separated byonly 5.6 arc seconds with very similar redshifts, magnitudes,and spectra . They concluded that perhaps they were seeing the same object twice, due to the lensing of a closer,massive object. Similar observations were made by Lynds and V . Petrosian in 1988, in which they saw multiple arcletswithin clusters.
We can study a distant galaxy’s distorted image and make conclusions about the amount of mass within a lensingcluster using this expression for θ E, the “Einstein radius” the radius of an arclet in radians whereGis the gravitational constant, Mis the mass of the lens, cis the speed of light,and dLS,dL,a n ddSare the distance between the lens and source, the distanceto the lens, and the distance to the source, respectivelynote these distances are angulardiameter distances whichdiﬀer from our “ordinarily” notion of distance, called the proper distance, due to the expansion and curvature of theUniverse. Physicists have found that this calculated mass is much larger than the mass that can be inferred from a cluster’s luminosity. For example, for the lensing cluster Abell370, Bergmann, Petrosian, and Lynds determined that theML ratio of the cluster must be about 10 necessitating the existence of large amounts of dark matterin the cluster as well as placing constraints on its distributionwithin the cluster.
3. Modern Understanding and Evidence 3.1. Microlensing. T o explain dark matter physicists ﬁrst turned to astrophysical objects made of ordinary, baryonicmatter the type of matter that we see every day and is madeup of fundamental particles called quarks, which we willdiscuss in further detail in Section 4 . Since we know that dark matter must be “dark,” possible candidates includedbrown dwarfs, neutron stars, black holes, and unassociatedplanets all of these candidates can be classiﬁed as MACHOsMAssive Compact Halo Objects.
T o hunt for these objects two collaborations, the MACHO Collaboration and the EROS2 Survey, searchedfor gravitational microlensing the changing brightness ofa distant object due to the interference of a nearby objectcaused by possible MACHOs in the Milky Way halo. Othercollaborations have studied this as well, such as MOA, OGLE,and SuperMACHO . The MACHO Collaboration painstakingly observed and statistically analyzed the skies for such lensing 11.9 million stars were studied, with only 13–17 possible lensing events detected . In April of 2007, the EROS2 Survey reported even fewer events,observing a sample of 7 million bright stars with only one lensing candidate found . This low number of possible MACHOs can only account for a very small percentage of thenonluminous mass in our galaxy, revealing that most darkmatter cannot be strongly concentrated or exist in the formof baryonic astrophysical objects. Although microlensings u r v e y sr u l eo u tb a r y o n i co b j e c t sl i k eb r o w nd w a r f s ,b l a c kholes, and neutron stars in our galactic halo, can other formsof baryonic matter make up the bulk of dark matter? Theanswer, surprisingly, is no, and the evidence behind this.
4 Advances in Astronomy claim comes from Big Bang Nucleosynthesis BBN and the Cosmic Microwave Background CMB.
3.2. Cosmological Evidence. BBN is a period from a few seconds to a few minutes after the Big Bang in the early,hot universe when neutrons and protons fused togetherto form deuterium, helium, and trace amounts of lithiumand other light elements. In fact, BBN is the largest sourceof deuterium in the Universe as any deuterium found orproduced in stars is almost immediately destroyed by fusingit into 4He thus the present abundance of deuterium in the Universe can be considered a “lower limit” on the amount ofdeuterium created by the Big Bang. Therefore, by consideringthe deuterium to hydrogen ratio of distant, primordiallikeareas with low levels of elements heavier than lithium anindication that these areas have not changed signiﬁcantlysince the Big Bang, physicists are able to estimate theDH abundance directly after BBN it is useful to look atthe ratio of a particular element’s abundance relative tohydrogen. Using nuclear physics and known reaction rates,BBN elemental abundances can be theoretically calculated one of the triumphs of the Big Bang model is the precise agreement between theory and observational determinationsof these light elemental abundances. Figure 2 shows theo retical elemental abundances as calculated with the BBNcode nuc123 compared with experimental ranges . It turns out that the DH ratio is heavily dependent on theoverall density of baryons in the Universe, so measuringthe DH abundance gives the overall baryon abundance.This is usually represented by Ω bh2,w h e r eΩbis the baryon density relative to a reference critical density ρca n d hH100 km sec−1Mpc−1the reduced Hubble constant, which is used because of the large historical uncertaintyin the expansion rate of the Universe. Cyburt calculatedtwo possible values for Ω bh2depending on what deuterium observation is taken Ωbh20.02290.0013 and Ωbh2 −0.0021, both which we will see accounts for only about 20% of the total matter density.
The CMB, discovered by Penzias and Wilson in 1964 but theorized by others much earlier as an excess background temperature of about 2.73 K, is another way inwhich we can learn about the composition of the Universe. Immediately after the Big Bang, the Universe was an extremely dense plasma of charged particles and photons.This plasma went through an initial rapid expansion, then expanded at a slower, decreasing rate, and cooled for about 380,000 years until it reached what is known as the epochof recombination. At this time, neutral atoms were formed,and the Universe became transparent to electromagneticradiation in other words, photons, once locked to chargedparticles because of interactions, were now able to travelunimpeded through the Universe. The photons released fromthis “last scattering” exist today as the CMB.
COBE COsmic Background Explorer launched in 1989, veriﬁed two fundamental properties of the CMB1 the CMB is remarkably uniform 2.73 K across thesky and 2 the CMB, and thus the early universe, is anearly perfect blackbody vindicating the use of statistical10−1110−1010−910−8 Figure 2 Light elemental abundances versus the photon to baryon ratio,η. The horizontal lines show measured abundances of the respective elements and the vertical lines show the photon to baryon ratio as measured by WMAP.
thermodynamics to describe the early universe. Although the CMB is extraordinarily uniform, COBE’s Di ﬀerential Microwave Radiometer DMR discovered in its ﬁrst yearfundamental anisotropies ﬂuctuations within the CMB,beyond the signal due to our motion relative to the CMBframe and foregrounds, such as emission from dust in theMilky Way. These fundamental ﬂuctuations are due to twodiﬀerent e ﬀects. Large scale ﬂuctuations can be attributed to the SachsWolfe e ﬀect lower energy photons are observed today from areas that were more dense at the time of lastscattering these photons, once emitted, lost energy escapingfrom deeper gravitational potential wells. On small scales,the origin of the CMB anisotropies are due to what are calledacoustic oscillations. Before photon decoupling, protons andphotons can be modeled as a photonbaryon ﬂuid sinceelectrons are so much less massive than baryons we can eﬀectively ignore them here. This ﬂuid e ﬀectively goes through the following cycle 1 the ﬂuid is compressedas it falls into a gravitational well, 2 the pressure of theﬂuid increases until it forces the ﬂuid to expand outward,3 the pressure of the ﬂuid decreases as it expands untilgravity pulls it back, and 4 the process repeats until photondecoupling. Depending on the location in the cycle for aportion of the ﬂuid at photon decoupling, the photons whichemerge vary in temperature. The ﬂuctuations in the CMBare thus indications of both the initial density perturbationsthat allowed for the formation of early gravitational wells aswell as dynamics of the photonbaryon ﬂuid. In this mannerthe temperature ﬂuctuations of the CMB are dependent.
Advances in Astronomy 5 on the amount of baryons in the Universe at the time of.
Although the detection of the ﬂuctuations in the CMB was a major accomplishment, the magnitude of the temperature variations puzzled scientists. These fundamentalﬂuctuations in the CMB are incredibly small, only about 5μK, meaning that the CMB is uniform to 1 part in 105. In fact, these ﬂuctuations were too small to have solely accounted for the seeds of structure formation essentially, given the size of the CMB ﬂuctuations, thestructure of the Universe we see today would not havehad time to form. The problem is time ordinary matteronly becomes charge neutral at the epoch of recombination,and before that, due to electrostatic forces, matter cannoteﬀectively clump into gravitational wells to begin forming structure. The COBE results showed a need for an electricallyneutral form of matter that could jump start the structureformation process well before recombination.
WMAP Wilkinson Microwave Anisotropy Probe was launched in 2001 with the mission to more precisely measurethe anisotropies in the CMB. Located at the EarthSun L2point about a million miles from Earth, the satellite hastaken data continuously most recently having released ananalysis of seven years of operation and is able to detecttemperature variations as small as one millionth of a degree.Due to the increased angular resolution of WMAP andthrough the use of computer codes which can calculate theCMB anisotropies given fundamental parameters such as thebaryon density, we now know the total and baryonic matterdensities from WMAP whereΩmh2is the total matter density, and Ωbh2is the baryonic matter density. The ﬁrst essential observation isthat these two numbers are di ﬀerent baryonic matter is not the only form of matter in the Universe. In fact, the darkmatter density, Ω dmh20.11230.0035, is around 83% of the total mass density. Locally, this corresponds to anaverage density of dark matter ρ dm≈0.3G e Vcm3≈5× 10−28kgm3at the Sun’s location which enhanced by a factor of roughly 105compared to the overall dark matter density in the Universe due to structure formation. An analysis of theCMB allows for a discrimination between dark matter andordinary matter precisely because the two components act diﬀerently the dark matter accounts for roughly 85% of the mass, but unlike the baryons, it is not linked to the photonsas part of the “photonbaryon ﬂuid.” Figure 3 demonstrates this point extremely well small shifts in the baryon densityresult in a CMB anisotropy power spectrum a graphicalmethod of depicting the CMB anisotropies which are whollyinconsistent with WMAP and other CMB experiment data.
Analyses of the largescale structure of the Universe also yield evidence for dark matter and help break degeneraciespresent in the CMB data analysis. By calculating the distanceto galaxies using their redshifts, cosmologists have been ableto map out the approximate locations of more than 1.5million galaxies. For example, the Sloan Digital Sky Survey20004000Power spectrum μK260008000 WMAP 7years dataMultipole moment l100 1000 Figure 3 The CMB Anisotropy Power Spectrum for various values ofΩbandΩdmholding Ωtot1 with WMAP year 7 data.
The anisotropy power spectrum gives the level of temperatureﬂuctuations on patches of various angular scales, where a sphericalversion of a Fourier transform gives multipoles l, where roughly 180◦θ, withθthe angular scale in degrees.
SDSS has created 3D maps of more than 900,000 galaxies, 120,000 quasars, and 400,000 stars during its eight years ofoperation . In fact, galaxy counts have had a long and important history in cosmology in the 1950s and 60s radiogalaxy counts provided the earliest, hard evidence againstthe Steady State model. But how can galaxy counts giveevidence for dark matter? As discussed earlier, the currentstructure in the Universe is due to initial density ﬂuctuationswhich served as seeds for structure formation magniﬁedby the presence of dark matter. The most likely source ofthese initial density perturbations are quantum ﬂuctuationsmagniﬁed by inﬂation, a period of early rapid exponentialgrowth approximately 10 −35seconds after the Big Bang.
Under the assumption that these random ﬂuctuations are Gaussian, a single function, the power spectrum Pk, is suﬃcient to describe the density perturbations. From here ag i v e nPk can be used to theoretically calculate large scale structure. These statements are true, of course, onlystatistically. Furthermore, the converse is also true by measuring largescale structure galaxy counts and surveys onecan experimentally determine the power spectrum Pk. By obtaining the matter power spectrum from galaxy surveys,the amount of total matter and baryonic matter can befound the peak of Pk is sensitive to the value of Ω m, and the amount of baryons has e ﬀects on the shape of Pk through baryonic acoustic oscillations, that is, excesses in galaxies.
6 Advances in Astronomy separated at certain distances due to sound waves in the pre recombination plasma . Using these techniques, a ﬁnal study of the 2dF Galaxy Redshift Survey power spectrumfoundΩ m0.2310.021 andΩbΩm0.1850.046 a study based on data from SDSS yielded Ωm0.2860.018 andΩdmh20.022670.00058 . Note that these results agree with both CMB and BBN predictions.
Nbody simulations of largescale structure are another tool which have been used to demonstrate the need for darkmatter. These simulations often take weeks to complete onsuperclusters for example, MSII tracked over 10 billionparticles which each represent 6.89 ×106h−1Min a volume of 100h−1Mpc3to study dark matter halo structure and formation . Similarly, Di Matteo et al .ran simulations to study the role of black holes in structure formation using20–200 million particles in a volume of 33.75 h 50h−1Mpc3.Nbody simulations conﬁrm the need for dark matter. Simulations without dark matter do notform the familiar ﬁlament and voidtype structures seen inthe observable universe by SDSS and other surveys on theproper timescales. Additionally, scenarios run in which darkmatter is relativistic or “hot” ﬁnd that structure formationis retarded or “washedout” instead of enhanced thus notonly is dark matter needed, but more speciﬁcally, darkmatter must be “cold” or nonrelativistic during the periodof structure formation.
3.3. Most Recent Evidence. Recent evidence hailed as the “smokinggun” for dark matter comes from the Bulletcluster, the result of a subcluster the “bullet” colliding withthe larger galaxy cluster 1E 065756. During the collision,the galaxies within the two clusters passed by each otherwithout interacting a typical distance between galaxies isapproximately one megaparsec, or 3.26 million lightyears.However, the majority of a cluster’s baryonic mass existsin the extremely hot gas between galaxies, and the clustercollision at roughly six million miles per hour compressedand shock heated this gas as a result, a huge amountof Xray radiation was emitted which has been observedby NASA ’s Chandra Xray Observatory. Comparing thelocation of this radiation an indication of the locationof the majority of the baryonic mass in the clusters to amapping of weak gravitational lensing an indication of thelocation of the majority of the total mass of the clustersshows an interesting discrepancy the areas of strong Xray emission and the largest concentrations of mass seen through gravitational lensing are not the same. The majority of themass in the clusters is nonbaryonic and gravity “points” backto this missing mass.
The galaxy cluster known as MACS J0025.41222 is a second example of a powerful collision between two clusterswhich separated the luminous and dark matter within thetwo clusters. In mid2008, Brada ˇce ta l .found that the behavior of the matter within this cluster is strikingly similarto the Bullet Cluster the dark matter passed through thecollision while the intergalactic gas interacted and emittedXrays. These results rea ﬃrmed those of the Bullet Cluster and the need for collisionless dark matter as well as severelyconstraining MOND theories see the appendix for a brief description of MOND theories.
In May of 2007, NASA ’s Hubble Space T elescope HST detected a ringlike structure of dark matter, caused byanother collision of two massive galaxy clusters one to twobillion years ago . The dark matter in the two clusters collapsed towards the center, but some of it began to “slosh” back out, causing the ringshaped structure it now has.Overlapping the distribution of gravitational lensing with thebaryonic mass in the combined cluster just as with the Bulletcluster shows the largest discrepancy yet between luminousand dark matter.
In early 2009, Penny et al .released results of a study from a HST survey of the Perseus Cluster, which is located about250 million light years from Earth. They noticed that small,dwarf spheroidal galaxies are stable while larger galaxiesare being torn apart by tidal forces caused by the clusterpotential, a sign that a signiﬁcant amount of dark matter maybe holding the dwarf galaxies together. By determining theminimum mass required for these dwarf galaxies to survivethe cluster potential, Penny et al .were able to calculate the amount of dark matter needed in each galaxy. Theyspeciﬁcally studied 25 dwarf spheroidal galaxies within thecluster and found that 12 require dark matter in order tosurvive the tidal forces at the cluster center.
In conclusion, the evidence for dark matter on scales from dwarf galaxies to clusters to the largest scales inthe Universe is compelling. There is remarkable agreementbetween multiple lines of evidence about the need for colddark matter. Having established the need for dark matter, in the next section we will discuss possible particle candidates for dark matter and how theories beyond the Standard Modelare necessary to solve the puzzle.
4. Particle Candidates Although the existence of dark matter is well motivatedby several lines of evidence, the exact nature of darkmatter remains elusive. Dark matter candidates are generically referred to as WIMPs Weakly Interacting Massive Particles in other words, they are massive particlesthat are electrically neutral which do not interact very strongly with other matter. In this section we will explore some possible particle candidates for dark matter andthe theories that lie behind them. But to begin with,we give a brief review of the Standard Model of particlephysics.
4.1. The Standard Model and the Neutrino. The Standard Model SM is the quantum ﬁeld theory that describes threeof the four fundamental forces in nature electricity andmagnetism, the weak nuclear force, and the strong nuclearforce. Gravitational interactions are not part of the SM atenergies below the Planck scale gravity is unimportant atthe atomic level. There are sixteen conﬁrmed particles in theSM, seven of which were predicted by the model before theywere found experimentally, and one particle yet to be seenthe Higgs boson, which is believed to be the mediator of.
Advances in Astronomy 7 the Higgs ﬁeld responsible for giving all other SM particles mass. In the SM, there are six quarks up, down, top, bottom,charm, and strange, six leptons electron, mu, tau, andtheir respective neutrinos, and ﬁve force carriers photons,gluons,W ,Z, and the Higgs boson. Quarks and leptons are classiﬁed as fermions with half integer spins and are split into three generations, where force carriers are classiﬁed as gauge bosons with integer spins. Each of these particles alsohas a corresponding antiparticle, denoted with a bar e.g., theup antiquark’s symbol is u, with opposite charge. Table 1 arranges the SM fundamental particles and some of theirbasic qualities.
SM particle interactions obey typical conservation of m o m e n t u ma n de n e r g yl a w sa sw e l la sc o n s e r v a t i o nl a w sfor internal gauge symmetries like conservation of charge,lepton number, and so on. The model has been thoroughlyprobed up to energies of ≈1 T eV , and has led to spectacular results such as the precision measurement of the anomalousmagnetic moment of the electron analogous to measuringthe distance between New Y ork and Los Angeles to the widthof a human hair.
The ﬁnal undiscovered particle, the Higgs boson, is thought to be extremely massive the latest bounds from theCDF and D ∅collaborations at the T evatron have restricted the mass of the Higgs to two regions 114–160 GeV and 170–185 Gev . Since the Higgs boson couples very weakly to ordinary matter it is di ﬃcult to create in particle accelerators.
Hopefully, the powerful Linear Hadron Collider LHC inGeneva, Switzerland, will conﬁrm the existence of the Higgsboson, the ﬁnal particle of the SM.
Despite its success, the SM does not contain any particle that could act as the dark matter. The only stable, electricallyneutral, and weakly interacting particles in the SM are theneutrinos. Can the neutrinos be the missing dark matter?Despite having the “undisputed virtue of being known toexist” as put so well by Lars Bergstrom, there are twomajor reasons why neutrinos cannot account for all of theUniverse’s dark matter. First, because neutrinos are relativistic, a neutrinodominated universe would have inhibitedstructure formation and caused a “topdown” formationlarger structures forming ﬁrst, eventually condensing andfragmenting to those we see today . However, galaxies have been observed to exist less than a billion years after theBig Bang and, together with structure formation simulations,a “bottomup” formation stars galaxies then large galaxiesthen clusters, etc. seems to be the most likely . Second, Spergel et al .ruled out neutrinos as the entire solution to missing mass using cosmological observations WMAPcombined with largescale structure data constrains theneutrino mass to m v0.23 eV , which in turn makes the cosmological density Ωvh20.0072 . While neutrinos do account for a small fraction of dark matter, they clearlycannot be the only source.
The lack of a dark matter candidate does not invalidate the SM, but rather suggests that it must be extended. Perhaps the SM is only a valid theory at low energies, and thatthere is new physics “beyond the Standard Model” that is,new theories may supplement, rather than replace, the SM.Such new theories have already been proposed, the mostpromising being supersymmetry, which also yields a viable dark matter candidate called the neutralino or LSP.
4.2. Problems of the Standard Model. Although very suc cessful, the SM has two ﬂaws which hint at the needfor new solutions the hierarchy problem and the ﬁnetuning problem. The hierarchy problem arises from the SM’sprediction of the Higgs vacuum expectation value vev, i.e.,the average value of the ﬁeld in the vacuum, which is about 246 GeV . Theorists have predicted that at high enough ≈1 T eV the electromagnetic and weak forces act as a single uniﬁed force called the electroweak force thishas also been experimentally veriﬁed. However at smallerenergies, the single uniﬁed force breaks down into twoseparate forces the electromagnetic force and the weak force.It turns out that after this breaking, the Higgs ﬁeld’s lowestenergy state is not zero, but the 246 GeV vacuum expectationvalue. It is precisely this nonzero value that gives otherparticles mass through their interactions with the Higgs ﬁeld.The 246 GeV vev is at the weak scale the typical energy ofelectroweak processes however, the Planck scale the energyat which quantum e ﬀects of gravity become strong is around 19GeV . The basic question, then, is why is the Planck scale 1016times larger than the weak scale? Is there simply a “desert” between 103and 1019GeV in which no new physics There is an additional di ﬃculty with the Standard Model.
Most calculations in a quantum ﬁeld theory are doneperturbatively. For example, the scattering cross section oftwo electrons at a given energy can be calculated up to acertain power of α, the ﬁne structure constant, which is the coupling constant for electromagnetism. The calculation isrepresented pictorially with Feynman diagrams the number of particle interaction vertices is related to the power of α.
However, virtual particles and more complicated diagramscan also contribute to the process with higher powers of α, several examples of which can be seen in Figure 4.
As an example, the best anomalous magnetic moment of the electron calculation involves 891 diagrams . Thus most quantities have socalled “quantumloop” correctionsalthough some quantities, like the photon’s mass, areprotected by symmetries. The ﬁnetuning problem ariseswhen trying to calculate the mass of the Higgs particlequantum loop corrections to the Higgs mass are quadratically divergent. If one uses 10 16GeV as the scale at which the electroweak and strong forces combine to become asingle uniﬁed force which has been theorized but not seen,one requires an almost perfect cancellation on the ordero f1p a r ti n1 0 14for the Higgs mass to come out at the electroweak scale ≈150 GeV. This unnatural cancellation is a source of alarm for theorists and signiﬁes that we lack anunderstanding of physics beyond the SM.
One possible extension to the Standard Model is supersymmetry SUSY. SUSY at its essence is an additionalsymmetry between fermions and bosons and can best be.
8 Advances in Astronomy Table 1 The particles predicted by the Standard Model. Approximate masses of particles as last reported by the Particle Data Group.
Generation 1 Generation 2 Generation 3 Particle Mass MeV Charge Particle Mass MeV Charge Particle Mass MeV Charge up quark u2 . 5 52 3charm quark c 1270 2 3top quark t 171200 2 down quark d5 . 0 4 −1 3strange quark s 104 −1 3bottom quark b 4200 −1 electron e− 0.511 −1m u o n μ− 105.7 −1t a u τ− 1776.8 −1 eneutrino νe2.0×10−60μneutrino νμ0.19 0 τneutrino ντ18.2 0 b Gauge Bosons Particle Force Acts through Acts on Mass MeV Charge Photon γ Electromagnetic Electric charge Electrically charged particles 1×10−24≈00 Zboson Z Weak nuclear Weak interaction Quarks and leptons 91188 0 Wbosons W Weak nuclear Weak interaction Quarks and leptons 80398 1 Gluon g Strong nuclear Color charge Quarks and gluons 0 0 Higgs boson H0 Higgs force Higgs ﬁeld Massive particles 114400 0 a b c Figure 4 The tree level diagram on the left represents the electronelectron scattering process to the lowest order in perturbation theory.
The two graphs on the right represent higher order processes which can be thought of as loop corrections and enter with higher powers.
understood by beginning with the ColemanMandula the orem. The ColemanMandula theorem states that the most general symmetries that a quantum ﬁeld theory QFT can possess are Lorentz invariance special relativity and gaugesymmetries like conservation of charge, lepton number, andso on. whose generators belong to Lie Algebras . In other words, the ColemanMandula theorem is a “nogo”theorem a relativistic QFT can have no other symmetries.In particular, there can be no change of the spin of particles.That is, there is no way in the SM to change fermions tobosons or viceversa.
However, in the mid1970s two groups of physicists realized that the ColemanMandula theorem can be evaded.Supersymmetry evades the restriction of the ColemanMandula theorem by generalizing and loosening the restriction on the types of symmetries of a QFT in addition toLie Algebras one can consider graded Lie Algebras whoseoperators anticommute. This additional symmetry allowsfor the interconversion of fermions and bosons. Essentially,every fermion is now associated with a superpartner bosonand every boson with a superpartner fermion addingsupersymmetry to the standard model e ﬀectively doubles the number of particles. Although doubling the number ofparticles may seem a hopeless complication, supersymmetryis very attractive theoretically for a number of reasons.T o begin with, supersymmetry may solve the hierarchy and the ﬁnetuningnaturalness problem in the Standard Model. SUSY is new physics which acts at energies beyond the SM which helps to explain why the electroweak andPlanck energy scales are so di ﬀerent. In terms of the ﬁne tuning problem, SUSY can explain why the Higgs massand the Higgs vev are so small. If SUSY were an exactsymmetry of nature, then the mass of each SM bosonicparticle must be equal to its superpartner fermion mass.And since boson and fermion mass corrections in QFTcalculations enter with opposite signs, they can canceleach other leading to a “naturally” small Higgs massand vev. Of course supersymmetry is a broken symmetry, meaning that the symmetry is no longer valid atthe typical energies and background temperatures in theUniverse today. For example, we do not see a bosonicsuperpartner to the electron with .511 MeV mass whichwould be a sign of unbroken supersymmetry. Due to thisbreaking which is not well understood all superpartnersmust be extremely massive much like the WandZ particles acquire mass in electroweak symmetry breakingwhile the photon remains massless. In order to produceacceptable corrections to the Higgs mass, the di ﬀerence between boson and fermion masses must be of the order of1T e V ..
Advances in Astronomy 9 Furthermore, precision measurements of Standard Mod el parameters at the LEP collider show that using onlythe Standard Model particle content the strong, weak, andelectromagentic forces do not seem to unify at energies ofabout 10 16GeV . Particle physicists have long predicted that like the weak and electromagnetic forces which unify at energies of about 103GeV , the three quantum forces should merge to become a single Grand Uniﬁed Force. However, ifone adds the minimal particle content of supersymmetry, thecouplings indeed seem to converge at a uniﬁcation scale ofM similarequal2×1016GeV . Additionally, supersymmetry is inherent in string theory, which currently is the only theorywhich has the possibility of unifying the quantum world withgravity.
And ﬁnally, and this is perhaps the most appealing characteristic of supersymmetry, the Standard Model withSUSY does in fact o ﬀer a viable dark matter candidate which we will discuss shortly. The new particles generated by addingSUSY to the SM are shown below in Table 2.
When examining the particle content of the SM with SUSY, there are several possible particles which could actas dark matter. These are the neutralino a particle statewhich is a superposition of the neutral superpartners of theHiggs and gauge bosons, the sneutrino the superpartnerof the neutrino, and the gravitino the superpartner ofthe graviton which would come from a quantum theory ofgravity. All of these particles are electrically neutral andweakly interacting, and thus are ideal WIMPlike candidatesfor dark matter. However, sneutrinos annihilate very rapidlyin the early universe, and sneutrino relic densities are too low to be cosmologically signiﬁcant . And gravitinos act as hot dark matter rather than cold dark matter, and largescale structure observations are inconsistent with a universedominated by hot dark matter . This leaves the neutralino as a viable candidate.
But how can the neutralino, an extremely massive particle, exist today in su ﬃcient numbers to make up the bulk of the dark matter generically, massive particles decayinto lighter ones? The answer lies in what is called Rparity.In the Standard Model symmetries guarantee baryon andlepton number conservation for this reason, the proton, thelightest baryon, cannot decay. However, with the additiono fs u p e r s y m m e t r y ,t h i si sn ol o n g e rg e n e r a l l yt r u ed u et othe presence of squarks and sleptons recall, SUSY changesquarks and leptons into bosons and viceversa, so baryon andlepton number are violated as a matter of course. However,we know that the amount of baryon and lepton numberviolation at least at low energies must be extremely smalldue to sensitive tests. An interesting property of SUSY isthat if one writes down a theory without lepton and baryonnumber violating terms, no such terms will ever appear,even through quantum loop corrections another advantage of SUSY is that certain types of quantities never get loop corrections. Under this assumption, a new symmetry, calledRparity, may be conserved by a SUSY version of the SM. Weassign 1 Rparity for all Standard Model ﬁelds includingboth Higgs ﬁelds, and −1 Rparity for all superpartners.
The immediate consequence of Rparity conservation is thatbecause there are an even number of SUSY particles in everyinteraction, the lightest supersymmetric partner, the LSP , is stable and will not decay. If this LSP is neutral, it is anexcellent candidate for dark matter.
In most SUSY versions of the standard model, the neutralino is the LSP and seems to be the most promisingdark matter candidate the relic abundance of neutralinos canbe sizeable and of cosmological signiﬁcance, and detectionrates are high enough to be accessible in the laboratorybut not high enough to be experimentally ruled out. Thusthe SM with SUSY o ﬀers a single dark matter candidate the neutralino. Although at present not one supersymmetricparticle has been detected in the laboratory, supersymmetrycurrently o ﬀers the best hope of modeling and understanding dark matter. One clear advantage is that the minimalextension of the Standard Model using supersymmetry iswell understood, and calculations, including dark matterdensities and detection rates, can be performed.
6. Exotic Candidates Although the neutralino and SUSY are wellmotivated, otherparticle candidates for dark matter also exist. The axion isa particle proposed in 1977 by Roberto Peccei and HelenQuinn to solve the socalled “strongCP problem” . In a nutshell, the strong force Lagrangian contains a term thatcan give an arbitrarily large electric dipole moment to theneutron since no electric dipole moment for the neutronhas ever been observed, Peccei and Quinn postulated thata new symmetry prevents the appearance of such a termmuch like a gauge symmetry keeps the photon massless.They further theorized that this symmetry is slightly brokenwhich leads to a new, very light scalar particle, the axion.Although this particle is extremely light theories place itsmass in the μeV range, it can exist in su ﬃcient numbers to act as cold dark matter. Since axions should couple tophotons, axions can be searched for with precisely tunedradio frequency RF cavities inside the magnetic ﬁeld of anRF cavity the axion can be converted into a photon whichshows up as excess power in the cavity. And in a uniqueblend of particle and astrophysics, limits on axions have been placed through observations of red giant stars axions, if they existed, would o ﬀer another cooling mechanism which can be constrained by studying how quickly red giant starscool . Although the axion has never been observed directly, several experiments such as ADMX and CARRACKare continuing the search and setting new limits on axionparameters.
If axions exist and SUSY is also correct, then the axino the supersymmetric partner of the axion is by awide margin the LSP neutralinos would decay into axinosthroughχ →tildewideaγ. However, axinos would also act as hot dark matter and thus could not compose the bulk of thedark matter.
One ﬁnal exotic particle candidate for dark matter comes from theories of extra spatial dimensions. The idea thatour universe could have extra spatial dimensions beganin the 1920s with Theodor Kaluza and Oscar Klein bywriting down Einstein’s general theory of relativity in ﬁve.
Advances in Astronomy 11 direction and homogeneous that the Universe is roughly the same at every point in space the two points form thesocalled cosmological principle which is the cornerstoneof modern cosmology and states that “every comovingobserver in the cosmic ﬂuid has the same history” our placein the Universe is in no way special. The mathematical basis of the model is Einstein’s general relativity and it is experimentally supported by three key observations theexpansion of the Universe as measured by Edwin Hubble inthe 1920s, the cosmic microwave background, and Big BangNucleosynthesis.
The Friedmann equations are the result of applying general relativity to a four dimension universe which ishomogeneous and isotropic whereHis the Hubble constant which gives the expansion rate of the Universe and is not really a constant but changesin time,kis the spatial curvature of the Universe today, Gis Newton’s gravitation constant, and pandρare the pressure and energy density respectively of the matter and radiationpresent in the Universe. ais called the scalefactor which is a function of time and gives the relative size of the Universeais deﬁned to be 1 at present and 0 at the instant of the Big Bang, and sis the entropy density of the Universe. The Friedmann equations are actually quite conceptually simpleto understand. The ﬁrst says that the expansion rate of the Universe depends on the matter and energy present in it.
The second is an expression of conservation of energy andthe third is an expression of conservation of entropy percomoving volume a comoving volume is a volume whereexpansions e ﬀects are removed a nonevolving system would stay at constant number or entropy density in comovingcoordinates even through the number or entropy density isin fact decreasing due to the expansion of the Universe.
The expansion rate of the Universe as a function of time can be determined by specifying the matter or energy contentthrough an equation of state which relates energy density topressure. Using the equation of state ρ wp,w h e r ewis a constant one ﬁnds wheret0represents the present time such that at01 as stated earlier. For nonrelativistic matter where pressureis negligible, w 0a n dt h u s a∝t23 and for radiation and highly relativistic matter w13a n dt h u s a∝t12.
Although the real universe is a mixture of nonrelativisticmatter and radiation, the scale factor follows the dominantcontribution up until roughly 47,000 years after the BigBang, the Universe was dominated by radiation and hencethe scale factor grows like t 12. Since heavy particles like dark matter were created before nucleosynthesis which occurredminutes after the Big Bang, we shall treat the Universe as radiation dominated when considering the production ofdark matter.
7.2. Thermodynamics in the Early Universe. Particle reactions and production can be modeled in the early universe usingthe tools of thermodynamics and statistical mechanics. Inthe early universe one of the most important quantities tocalculate is the reaction rate per particle wherenis the number density of particles, σis the cross section the likelihood of interaction between the particlesin question, and vis the relative velocity. As long as Γ Ht we can apply equilibrium thermodynamics basically this measures if particles interact frequently enough oris the expansion of the Universe so fast that particles never encounter each other. This allows us to describe a system macroscopically with various state variables V volume, Ttemperature, Eenergy, Uinternal energy, Henthalpy, Sentropy, and so on. These variables are path independent so long as two systems begin and end atthe same value of a state variable, the change in that variablefor both systems is the same. The most relevant quantity inthe early universe is temperature. Since time and temperatureare inversely correlated, that is, the early universe is hotterthe exact relationship is that T ∝1a, we can rewrite the Hubble constant and reaction rates and cross sectionsin terms of temperature. The temperature will also tell usif enough thermal energy is available to create particlesfor example, if the temperature of the Universe is 10 GeV ,suﬃcient thermal energy exists to create 500 MeV particles from pair production, but not 50 GeV particles.
Statistical thermodynamics can be used to derive rela tions for the energy density, number density, and entropydensity of particles in the early universe in equilibrium. T o doso, BoseEinstein statistics are used to describe distributionsof bosons and FermiDirac statistics are used to describedistributions of fermions. The main di ﬀerence between the two arises from the Pauli exclusion principle which statesthat no two identical fermions can occupy the same quantum state at the same time. Bosons, on the other hand, canoccupy the same quantum state at the same time. Hence there aresmall di ﬀerences in the quantities we compute for bosons and fermions. T o obtain the relevant statistical quantities,we begin with the distribution factor. The distribution factor ip, which gives the relative numbers of particles with v a r i o u sv a l u e so fm o m e n t u m pfor a particle species i,i s ip2,μiis the chemical potential of species ienergy associated with change in particle number, and the 1 case describes bosons and the −1c a s ef e r m i o n s.
Y ou might notice that the Boltzmann constant kis missing from the denominator of the exponential. T o simplify things,.
Advances in Astronomy 13 terms cancel. This makes sense, because conversions and decays of SUSY particles do not a ﬀect the overall abundance of SUSY particles and therefore neutralinos, and thus makeno contribution to d ndt. We are left with wherenis the number density of neutralinos, angbracketleftσeﬀvangbracketrightis the thermal average of the e ﬀective annihilation cross section σeﬀtimes the relative velocity v,a n dneqis the equilibrium number density of neutralinos. A quick note should bemade about the thermal average angbracketleftσeﬀvangbracketrightand the added diﬃculty behind it. As thoroughly described by Schelke, coannihilations between the neutralinos and heavier SUSYparticles can cause a change in the neutralino relic densityof more than 1000%, and thus should not be left out of thecalculation . The thermal average is then not just the cross section times relative velocity of neutralinoneutralinoannihilation, but of neutralinoSUSY particle annihilationsas well many di ﬀerent possible reactions must be considered based upon the mass di ﬀerences between the neutralino and other SUSY particles.
By putting 17i nt e r m so f Y Tis the temperature to simplify the calculations, we obtain ∗is a parameter which depends on the e ﬀective degrees of freedom. Equation 18 can then be integrated fromx0t ox0mχT0to ﬁndY0which will be needed in 19 for the relic density.
Figure 5 adapted from Kolb and Turner’s excellent treat ment of this topic plots an analytical approximation to the Boltzmann Equation and illustrates several key points.Theyaxis is essentially or at least proportional to the relic density the solid line is the equilibrium value and thedashedline is the actual abundance. Notice that at freeze out, the actual abundance leaves the equilibrium value and remains essentially constant the equilbrium value, on theother hand, continues to decrease so freezeout is key topreserving high relic densities. Furthermore, the larger theannihilation cross section, angbracketleftσavangbracketright, the lower the relic density this makes sense since the more readily a particle annihilates,the less likely it will exist in large numbers today. This hasbeen paraphrased by many as “the weakest wins” meaningthat particles with the smallest annihilation cross sectionswill have the largest relic densities.
Using the value of Y 0described above, the relic density of neutralinos is given by wheremχis the mass of the neutralino, s0is the entropy density today which is dominated by the CMB photons sincethere are about 10 10photons per baryon in the Universe,−20−15−10log −50 1YeqYfor increasing σv Figure 5 The evolution of YxYx1 versus xmT where.
andY0is the result of integrating the modiﬁed version of the Boltzmann equation. For a more thorough discussion ofthe Boltzmann equation and the relic density of neutralinos,consult Schelke and Edsj ¨o and Gondolo.
Recall that the di ﬀerence between the matter and baryon densities as determined by WMAP was Ω 0.00311. Can particle models of dark matter like SUSY or KaluzaKlein theories produce dark matter in su ﬃcient quantities to act as the bulk of the dark matter? Theanswer generically is yes. Although SUSY theories cannotpredict a single dark matter relic density due to the inherentuncertainty in the input parameters, the Standard Modelplus supersymmetry does produce a wide range of modelssome of which have the expected dark matter density.For example, MSSM models the minimal supersymmetricstandard model yield dark matter relic densities from 10 of the WMAP results to some which overclose the Universeneutralino masses for the models which give a correct relicabundance typically lie in the range 50–1000 GeV . A similarcalculation can be performed for KaluzaKlein dark matter in the Universal Extra Dimension scenario Hooper and Profumo report that with the ﬁrst excitation of the photonas the LKP a relic abundance can be obtained in the properrange of 0 .095Ω dm0.129 for LKP masses between 850 and 900 GeV.
T o summarize, statistical thermodynamics allows us to model conditions in the early universe to predict relicabundances of dark matter particles like neutralinos. Whatis remarkable is that such models produce dark matterabundances consistent with the range provided by cosmological measurements. Theories like SUSY and KaluzaKlein theories are so powerful, in particular, because suchcalculations even given a wide range of uncertainty in.
Advances in Astronomy 15 modulation. These among other indications help detec tion experiments decide whether received signals really areWIMPs or not.
The interaction of a WIMP with the detector material can be classiﬁed by two characteristics elastic or inelastic, andspindependent or spinindependent.
i Elastic and inelastic scattering Elastic scattering is the interaction of a WIMP with the nucleus as awhole. This causes the nucleus to recoil and, as wehave seen, would deposit energies of around 25 keV.
In inelastic scattering all of the energy does not go into nuclear recoil instead the nucleus is excitedto a higher energy state e.g., the 52 73Ge which then decays by photon emission. If the excited state is longlived enough, the decay signalcan be separated from the nuclear recoil event thisleads to better background discrimination. However,inelastic scattering cross sections are generally smallerthan elastic scattering cross sections due to a lackof coherence the interaction is with individualnucleons rather than with the nucleus as a whole.
ii Spindependent and spinindependent scattering Spindependent “axialvector” scattering resultsfrom the coupling of a WIMP’s spin with the spincontent of a nucleon. Spinindependent “scalar”does not depend on this and has the advantageof higher cross sections with larger nuclei becauseof coherence where the WIMP interacts with thenucleus as a whole.
A recoil event can then be further categorized, taking on one of three forms.
i PhononThermal a vibration detected as a rise in temperature in the crystal lattice of the detector,caused by the slight movement of a nucleus o ﬀ which a WIMP has recoiled. An extremely sensitivethermometer system is located around the detector,allowing any temperature variation to be recorded.
ii Ionization an incident particle gives an electron in the detector enough energy to escape the pull of itsnucleus. A small electric ﬁeld is set up in the detectorto “push” the new charge to a detector wall where itcan be registered and counted as an ionization event.
iii Scintillation caused when an electron absorbs enough energy to climb to a higher energy state.After a short time, the electron will lose this energyby emitting a photon, which is then gathered byphotomultipliers and converted to an electric signalso it can be analyzed.
A detector is generally set up to sense two of these WIMP signals. By doing so, background events can be recognizedon an eventbyevent basis and discarded, allowing possibledark matter signatures to be counted and analyzed.T o calculate the number of recoil events Nexpected in a detector within a range of recoil energy E 1,E2, we take a sum over the nuclear species iin the detector where dRidEis the expected recoil rate per unit mass of iper unit nucleus recoil energy and per unit time, and εiE is the eﬀective exposure of iin the detector. d RidEis given by whereρis the local halo dark matter density, σiis the WIMP nucleus cross section, FiE is the nuclear form factor which takes into account that a nucleus is not a simple pointparticle,mis the WIMP mass, μ iis the reduced mass, vis the velocity of the WIMP with respect to the detector, Miis the mass of a nucleus of species i,Eis the recoil energy, and fvectorv,t is the WIMP velocity distribution generally assumed to be a MaxwellBoltzmann distribution in the referenceframe of the detector. The nuclear physics uncertainties arelocked into F iE while the astrophysical uncertainties lie in the WIMP velocity distribution. EiEi sg i v e nb y where Mis the total mass of nuclei of species iin the detector that has been active for a time Ti,a n depsilon1iE is the counting eﬃciency for nuclear recoils of energy E.
We can see from these expressions that a detector should ideally have a large mass with which to receive signals,be operational for a long period of time, and be properlyshielded against background radiation. An upper limit canbe put on the WIMPnucleus cross section by comparingexpected events using the above expressions to observation.Any negative results from direct detection experiments arenot wasted time and e ﬀort instead, we can say that the WIMP does not exist in a certain tested area of the parameterspace for a given dark matter theory and look towardmore sensitive areas. Fortunately, experiments are reachingmore advanced detection techniques and are approachingthe parameter space in which WIMPs are believed to exist.
While many others are in operation worldwide, the three direct detection experiments which have yielded thebest most constrained results for the spinindependent WIMPnucleus cross section are the Cryogenic Dark Matter Search CDMS II in the Soudan Mine, the UK Dark MatterCollaboration’s ZEPLINI ZonEd Proportional scintillationin LIquid Noble gases in the Boulby Mine, and XENON10at the Gran Sasso Underground Laboratory.
Each of these three collaborations uses a di ﬀerent method to look for WIMPs. CDMS II uses a set of 250 gram Gedetectors and 100 gram Si detectors cooled to less than50 mK. Each apparatus is classiﬁed as a ZIP Zdependent Ionization and Phonon detector. While WIMPs recoil o ﬀ of nuclei, background particles scatter o ﬀof electrons the ZIP detectors are able to discriminate between the two events. ZEPLINIII uses the scintillation properties of liquid Xe.
Advances in Astronomy 17 The EGRET Collaboration reported an excess of gamma rays in 1998, pointing toward already accepted characteristicsof dark matter a 50–70 GeV WIMP mass and a ring ofconcentrated dark matter at a radius of 14 kpc from thegalactic center which would nicely answer for our ﬂatrotation curves . This discovery is initially encouraging, but as Bergstr ¨om et al .have shown, observed antiproton ﬂuxes would have to be much larger if these excess gammarays are being produced by neutralino or generic WIMPself annihilation . For this reason and others, EGRET’s results remain controversial.
8.3.2. Neutrinos. Neutrinos can be another important prod uct of WIMP annihilation. As WIMPs travel through the Universe and through matter, they lose small amounts ofenergy due to scattering o ﬀof nuclei. Therefore, WIMPs can gather at the centers of large gravitating bodies, increasingtheir density until their annihilation rate equals half thecapture rate two WIMPs are needed for annihilation,where only one is needed for capture. For many of theprimary particle physics models, the WIMP annihilation andcapture rates are at or nearly at equilibrium in the Sun,a conveniently “close” object to observe. This equilibriumshould allow for a steady annihilation rate, and therefore aconstant ﬂow of neutrinos emanating from within the Sunwe study only the neutrinos and not other products ofannihilation because neutrinos interact so weakly that mostescape from the Sun or body in question. Why not, then,study neutrinos coming from WIMP annihilations withinthe Earth, an even closer gravitating body? The earth in mostmodels has not reached such an equilibrium and thus doesnot provide a ﬂux of neutrinos it is less massive than theSun, so it causes less WIMP scattering and a much smallergravitational potential well. Neutrino telescopes thereforeusually focus on neutrino ﬂux coming from the Sun, ratherthan the Earth.
The di ﬀerential neutrino ﬂux from WIMP annihilation is whereΓAis the annihilation rate of WIMPs in the Sun andor Earth,Dis the distance of the detector from the source the central region of the Sun andor Earth, fis the WIMP pair annihilation ﬁnal states, and Bf Xare the branching ratios of the ﬁnal states. dNf νdE νare the energy distributions of neutrinos generated by the ﬁnal state Depending on the WIMP’s mass and composition, annihilation processesincludeχχ →tt,bb,cc,ZZ,WW−,a n dττ−, which then decay to neutrinos among other products. For neutralinosor generic WIMPs lighter than W , annihilation to bband ττ−are the most common processes, yielding neutrinos with energies around 30 GeV . WIMPs with higher massesannihilate to Higgs and gauge bosons, top and bottomquarks, and muons, leading to neutrinos of masses thatare much easier to detect about half of the WIMP mass.Detection, then, depends heavily on the WIMP mass, as wellas the annihilation rate, density within the Sun, and other.
As neutrinos pass through the Earth, they sometimes interact with the hydrogen and oxygen and other atomsaround the optical modules of a neutrino detector. Electrons,muons, and taus produced by such events are extremely energetic and are traveling faster than the speed of light in the medium the particles are then detected optically due tothe Cherenkov radiation they emit.
Because neutrinos are so weakly interacting, neutrino telescopes must be massive to detect a signiﬁcant signal.AMANDAII is a neutrino detector 1500 to 2000 metersunderground within the ice of the South Pole whereCherenkov radiation can travel and be seen easily by opticalmodules. This experiment has not detected statisticallysigniﬁcant results from the direction of the Sun, but hasplaced helped place ﬁrm limits on the muon ﬂux.
A future experiment expected to be fully completed in2011, IceCube, will integrate AMANDA into a muchlarger detection experiment, with 7200 optical modulesand a detector volume of a cubic kilometer . Super Kamiokande “SuperK” is another indirect detectionexperiment, located underground in the KamiokaMozumimine in Japan. The detector consists of 50,000 tons of waterand detects Cherenkov radiation from incoming muons aswell. SuperK looks in the direction of the Sun, earth, andgalactic center, and, like AMANDA, has not detected anyexcess of muon rates above the expected background.
8.3.3. Antimatter. Antimatter can be a excellent signal of WIMP annihilation precisely because antimatter is relativelyrare cosmically, and many of the astrophysical processes which create antimatter are well understood. For example, the annihilation of WIMPs can also produce antiprotonsviaχχ →qqthrough hadronization where the dominate annihilation process yields bquarks and antiquarks, and positrons through secondary products of the annihilation such asWW−andZZ, whereWorZ→eve. Unlike gammarays and neutrinos, these products are chargedand thus a ﬀected by magnetic ﬁelds within space and also lose energy due to inverse Compton and synchrotron processes, so we cannot make any conclusions about wherethe annihilations occurred. We therefore study the ﬂux ofantimatter particles from the galactic halo as a whole, rather than assumed dense areas such as the galactic center or large.
Experiments searching for antimatter must be located near the top of the Earth’s atmosphere various other cosmicrays and their consequential particle showers create too large and uncertain of a background to make conclusive analyses. It is important, however, to still consider andsubtract any background caused by cosmic rays that reach theedges of our atmosphere. In 1994, the HEAT Collaboration detected an excess of cosmic ray positrons of energies around 10 GeV possibly caused by neutralino selfannihilation, and conﬁrmed this signal again in 2000 . A “boost factor,” however, must be applied to the WIMP annihilation rateof a smooth halo in order to match the HEAT data this.
Advances in Astronomy 19 MOND MOdiﬁed Newtonian Dynamics. In 1983 Milgrom proposed that the ﬂat rotation curves observed in manygalaxies may be explained without postulating any sort ofmissing mass in the Universe . He instead introduced an acceleration constant to modify Newton’s second law,which would at small accelerations account for the radius independent nature of stellar motion.
Rather than the usual vectorF mvectora, the equation at the heart of MOND is wherevectorFis the force acting on an object of mass mand acceleration avectora,a n da0≈2×10−8cm s−2is the acceleration constant determined by Milgrom many otherMOND theories have emerged with di ﬀering values for For accelerations greater than or equal to a0most accelerations we see in every day life, including the motionsof planets within our solar system, x ≈1, and Newtonian dynamics can be used as usual. However, for very smallaccelerations such as for the orbits of objects far awayfrom the galactic center, a 0becomes signiﬁcant this is how MOND predicts and explains the ﬂat rotation curves.
T o demonstrate how MOND can explain ﬂat rotation curves, we ﬁrst consider the expression for the force of gravity vectorFon a star and Milgrom’s modiﬁcation of Newton’s second whereGis the gravitational constant, mandMare the masses of the star and galaxy respectively, and ris the radius of the s t a r ’ so r b i t .I fw ec a n c e l mfrom both sides and assume that μaa 0aa 0 at a very large r, we are left with Solving for aand using the relationship of acceleration with velocity and radius av2r, we ﬁnd r, and therefore, wherevhas no dependence on This relation has allowed various studies to use MOND to ﬁt ﬂat rotation curvesquite successfully for several low and high surface brightnessgalaxies LSB and HSB galaxies, resp. based on luminousmass alone . As MOND predicts, LSB galaxies show a larger departure from Newtonian dynamics where HSBgalaxies show discrepancies only in their outer regions wheregravitational attraction is considerably smaller. MOND andT eVeS the MONDian version of General Relativity have had success in predicting and describing other observedgalactic dynamics as well. For a recent review, see Sanders.
Despite these successes, MOND faces several major and critical challenges it has not been able to overcome. Forexample, when considering galaxy clusters, MOND cannotaccount for density and temperature proﬁles and requires unseen matter . Evidence for dark matter exists on many distance scales and MOND essentially only works ongalactic scales. Also, extremely low acceleration experimentsbelowa 0 have been conducted, ﬁnding no departure from Newton’s second law and thus constraining MOND to reduceto Newton’s second law in laboratory conditions.
And ﬁnally, gravitational lensing evidence such as in theBullet Cluster show that, in e ﬀect, the gravitational force points back not towards regular, observed baryonic matterbut rather some form of dark matter which is not observedoptically. MOND theories in their current forms cannotaccount for such a discrepancy easily, although more recenttheories which wed MOND with a sterile neutrino are beingdeveloped . However, for the above reasons and others, we feel that dark matter is a more promising solution to thepuzzle of missing mass in the Universe.
Advances in Astronomy 21 Randall and Sundrum, “Large mass hierarchy from a small extra dimension,” Physical Review Letters , vol. 83, no.
Submit your manuscripts at Hindawi Publishing Corporation httpwww.hindawi.com Volume 2014High Energy PhysicsAdvances in The Scientific Hindawi Publishing Corporation httpwww.hindawi.com Volume 2014 Hindawi Publishing Corporation httpwww.hindawi.com Volume 2014FluidsJournal of Atomic and Molecular PhysicsJournal of Hindawi Publishing Corporation httpwww.hindawi.com Volume 2014 Hindawi Publishing Corporation httpwww.hindawi.com Volume 2014Advances in Condensed Matter Physics OpticsInternational Journal of Hindawi Publishing Corporation httpwww.hindawi.com Volume 2014 Hindawi Publishing Corporation httpwww.hindawi.com Volume 2014AstronomyAdvances in International Journal of Hindawi Publishing Corporation httpwww.hindawi.com Volume 2014Superconductivity Hindawi Publishing Corporation httpwww.hindawi.com Volume 2014Statistical MechanicsInternational Journal of Hindawi Publishing Corporation httpwww.hindawi.com Volume 2014GravityJournal of Hindawi Publishing Corporation httpwww.hindawi.com Volume 2014AstrophysicsJournal of Hindawi Publishing Corporation httpwww.hindawi.com Volume 2014Physics Hindawi Publishing Corporation httpwww.hindawi.com Volume 2014Solid State PhysicsJournal of Methods in PhysicsJournal of Hindawi Publishing Corporation httpwww.hindawi.com Volume 2014 Hindawi Publishing Corporation httpwww.hindawi.com Volume 2014Soft MatterJournal of Hindawi Publishing Corporation Hindawi Publishing Corporation httpwww.hindawi.com Volume 2014PhotonicsJournal of Hindawi Publishing Corporation httpwww.hindawi.com Volume 2014Journal of Hindawi Publishing Corporation Volume 2014.
